
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>用python爬取网页内容 | L技术小筑</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=3, minimum-scale=1">
    
    <meta name="author" content="John Doe">
    
    <meta name="description" content="引入各种模块代码如下:
123456from bs4 import BeautifulSoupimport requestsimport reimport threadingimport csvimport os,time,random
如果import下有红色的波浪线,则是因为改模块未安装,需要通">
    
    
    
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/yaht.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/yaht.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      <div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="L技术小筑" title="L技术小筑"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="L技术小筑">L技术小筑</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
					<li>
					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="text" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:yoursite.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>

    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/08/06/用python爬取网页内容/" title="用python爬取网页内容" itemprop="url">用python爬取网页内容</a>
  </h1>
  <p class="article-author">By
    
      <a href="http://yoursite.com" title="John Doe">John Doe</a>
    </p>
  <p class="article-time">
    <time datetime="2018-08-06T00:30:44.000Z" itemprop="datePublished">2018-08-06</time>
    Updated:<time datetime="2018-08-07T00:42:05.182Z" itemprop="dateModified">2018-08-07</time>
    
  </p>
</header>
	<div class="article-content">
		
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">Contents</strong>
		<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#引入各种模块"><span class="toc-number">1.</span> <span class="toc-text">引入各种模块</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#获取网页内容"><span class="toc-number">2.</span> <span class="toc-text">获取网页内容</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#对内容进行整理"><span class="toc-number">3.</span> <span class="toc-text">对内容进行整理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#处理接收到的内容"><span class="toc-number">3.1.</span> <span class="toc-text">处理接收到的内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#查找title标签的中的内容"><span class="toc-number">3.2.</span> <span class="toc-text">查找title标签的中的内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#查找所有P标签"><span class="toc-number">3.3.</span> <span class="toc-text">查找所有P标签</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#查看P标签中是否包含图片"><span class="toc-number">3.3.1.</span> <span class="toc-text">查看P标签中是否包含图片</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#将P标签中的内容提取出来"><span class="toc-number">3.3.2.</span> <span class="toc-text">将P标签中的内容提取出来</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#将爬去的内容存储到文件中"><span class="toc-number">3.4.</span> <span class="toc-text">将爬去的内容存储到文件中</span></a></li></ol></li></ol>
		</div>
		
		<h1 id="引入各种模块"><a href="#引入各种模块" class="headerlink" title="引入各种模块"></a>引入各种模块</h1><p>代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> os,time,random</span><br></pre></td></tr></table></figure>
<p>如果<code>import</code>下有红色的波浪线,则是因为改模块未安装,需要通过<code>pip install 模块名</code>进行安装.</p>
<h1 id="获取网页内容"><a href="#获取网页内容" class="headerlink" title="获取网页内容"></a>获取网页内容</h1><p>用<code>requests</code>模块中的<code>get(网址)</code>函数来获取网页内容<br>并用<code>encoding</code>设置接收内容的编码格式  </p>
<p>代码如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">"https://mp.weixin.qq.com/s/aMxcnG7pd5C3H-6LRzgwcg"</span></span><br><span class="line">r = requests.get(url)</span><br><span class="line">r.encoding = <span class="string">"utf-8"</span></span><br></pre></td></tr></table></figure></p>
<h1 id="对内容进行整理"><a href="#对内容进行整理" class="headerlink" title="对内容进行整理"></a>对内容进行整理</h1><h2 id="处理接收到的内容"><a href="#处理接收到的内容" class="headerlink" title="处理接收到的内容"></a>处理接收到的内容</h2><p>接收内容,并通过<code>BeautifulSoup</code>处理接收内容.<br>[更多关于<code>BeautifulSoup</code>的使用内容][1]<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">html = r.text</span><br><span class="line"><span class="comment"># 'html.parser'意思是html解析器,还有'lxml'--lxml解析器,'html5lib'--html5lib解析器等</span></span><br><span class="line">soup = BeautifulSoup(html,<span class="string">'html.parser'</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="查找title标签的中的内容"><a href="#查找title标签的中的内容" class="headerlink" title="查找title标签的中的内容"></a>查找title标签的中的内容</h2><p>通过<code>get_text()</code>函数,可以直接获取title标签中的内容<br>如:<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>我是标题<span class="tag">&lt;<span class="name">title</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>通过<code>get_text()</code>则返回<code>我是标题</code>这一字符串.  </p>
<p>代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">soup.title.get_text()</span><br></pre></td></tr></table></figure>
<h2 id="查找所有P标签"><a href="#查找所有P标签" class="headerlink" title="查找所有P标签"></a>查找所有P标签</h2><p>通过<code>find_all()</code>函数可以获取所有P标签,并返回一个由 <strong>html对象</strong> 组成的数组(不是字符串,切记)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">soup.find_all(`p`)</span><br><span class="line"></span><br><span class="line"><span class="comment">#[&lt;p class="profile_meta"&gt;&lt;label class="profile_meta_label"&gt;微信号&lt;/label&gt;&lt;span class="profile_meta_value"&gt;zzuweixin&lt;/span&gt;&lt;/p&gt;,</span></span><br><span class="line"><span class="comment">#&lt;p class="profile_meta"&gt;&lt;label class="profile_meta_label"&gt;功能介绍&lt;/label&gt;&lt;span class="profile_meta_value"&gt;郑州大学官方微信公众平台&lt;/span&gt;&lt;/p&gt;, </span></span><br><span class="line"><span class="comment"># &lt;p style="text-align: center;letter-spacing: 0.5px;line-height: 1.75em;"&gt;&lt;span style="color: #595959;"&gt;泽厚万物 和合有为&lt;/span&gt;&lt;/p&gt;, &lt;p style="text-align: c#enter;letter-spacing: 0.5px;line-height: 1.75em;"&gt;&lt;span style="color: #595959;"&gt; 夏日的郑大校园渲染了青#春的色彩&lt;/span&gt;&lt;/p&gt;]</span></span><br></pre></td></tr></table></figure>
<h3 id="查看P标签中是否包含图片"><a href="#查看P标签中是否包含图片" class="headerlink" title="查看P标签中是否包含图片"></a>查看P标签中是否包含图片</h3><p>因为该站的图片放在P标签中,所以要把图片部分筛选出来,并通过获取图片地址,将图片保存在本地文件夹中</p>
<p>代码如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">pic_all = soup.find_all(<span class="string">'img'</span>)</span><br><span class="line"><span class="keyword">if</span> pic_all:</span><br><span class="line">    <span class="keyword">for</span> pic <span class="keyword">in</span> pic_all:</span><br><span class="line">        <span class="comment">#用当前时间戳给图片命名</span></span><br><span class="line">        filename = str(int(time.time()))+<span class="string">".jpg"</span></span><br><span class="line">        <span class="comment">#将html对象装换为字符串,为了获取图片地址</span></span><br><span class="line">        pstr = str(pic)</span><br><span class="line">        <span class="comment">#search是匹配任意位置的字符串,match是从头匹配,开头如果没有,直接返回none</span></span><br><span class="line">        img_src = re.search(<span class="string">r'(https[^"]+)'</span>, pstr).groups()[<span class="number">0</span>]</span><br><span class="line">        r = requests.get(img_src,stream=<span class="keyword">True</span>)</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'d/img/'</span>+filename, <span class="string">'wb'</span>) <span class="keyword">as</span> img_f:</span><br><span class="line">                <span class="keyword">for</span> chunk <span class="keyword">in</span> r.iter_content():</span><br><span class="line">                    img_f.write(chunk)</span><br></pre></td></tr></table></figure></p>
<p>或者:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">img_bs = con.find_all(<span class="string">"img"</span>)</span><br><span class="line">            <span class="keyword">for</span> img_single <span class="keyword">in</span> img_bs:</span><br><span class="line">                filename = str(int(time.time()))+str(i)+<span class="string">'.jpg'</span></span><br><span class="line">                <span class="comment">#img的"data-src"属性值是图片地址,img_src接收到的是一个字符串</span></span><br><span class="line">                img_src = img_single[<span class="string">'data-src'</span>]</span><br><span class="line">                r = requests.get(img_src,stream=<span class="keyword">True</span>)</span><br><span class="line">                <span class="keyword">with</span> open(<span class="string">'d/img/'</span>+filename, <span class="string">'wb'</span>) <span class="keyword">as</span> img_f:</span><br><span class="line">                    <span class="keyword">for</span> chunk <span class="keyword">in</span> r.iter_content():</span><br><span class="line">                        img_f.write(chunk)</span><br></pre></td></tr></table></figure></p>
<h3 id="将P标签中的内容提取出来"><a href="#将P标签中的内容提取出来" class="headerlink" title="将P标签中的内容提取出来"></a>将P标签中的内容提取出来</h3><p>代码如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">p = soup.find_all(<span class="string">'p'</span>)</span><br><span class="line">p_content = <span class="string">""</span></span><br><span class="line"><span class="keyword">for</span> p_one <span class="keyword">in</span> p:</span><br><span class="line">    p_content += p_one.get_text()</span><br></pre></td></tr></table></figure></p>
<h2 id="将爬去的内容存储到文件中"><a href="#将爬去的内容存储到文件中" class="headerlink" title="将爬去的内容存储到文件中"></a>将爬去的内容存储到文件中</h2><p>假设所有内容都放到了一个名为<code>data</code>的字典里,<code>title</code>属性是页面标题,<code>content</code>属性是页面内容<br>代码如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'new.txt'</span>,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(data[<span class="string">'title'</span>])</span><br><span class="line">    f.write(data[<span class="string">'content'</span>])</span><br></pre></td></tr></table></figure></p>
<p>大致做法就是如此</p>
<p>完整代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!python3</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> os,time,random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(link)</span>:</span></span><br><span class="line">    url = link</span><br><span class="line">    r = requests.get(url)</span><br><span class="line">    r.encoding = <span class="string">"utf-8"</span></span><br><span class="line">    <span class="comment"># pattern = re.compile(r'\/\/[\w]*\/')</span></span><br><span class="line">    <span class="comment"># dirn = pattern.findall(url)</span></span><br><span class="line">    <span class="comment"># print(dirn)</span></span><br><span class="line">    <span class="comment"># cur_dir = 'D:/python_web'</span></span><br><span class="line">    <span class="comment"># folder_name = dirn</span></span><br><span class="line">    <span class="comment"># if os.path.isdir(cur_dir):</span></span><br><span class="line">    <span class="comment">#     os.mkdir(os.path.join(cur_dir, folder_name))</span></span><br><span class="line">    html = r.text</span><br><span class="line">    soup = BeautifulSoup(html,<span class="string">'html.parser'</span>)</span><br><span class="line">    p = soup.find_all(<span class="string">'p'</span>)</span><br><span class="line">    data = &#123;&#125;</span><br><span class="line">    data[<span class="string">"title"</span>] = soup.title.get_text()+<span class="string">'\n'</span></span><br><span class="line">    data[<span class="string">'content'</span>] = <span class="string">""</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> con <span class="keyword">in</span> p:</span><br><span class="line">        <span class="keyword">if</span> con.find_all(<span class="string">"img"</span>):</span><br><span class="line">            img_bs = con.find_all(<span class="string">"img"</span>)</span><br><span class="line">            <span class="keyword">for</span> img_single <span class="keyword">in</span> img_bs:</span><br><span class="line">                filename = str(int(time.time()))+str(i)+<span class="string">'.jpg'</span></span><br><span class="line">                <span class="comment">#img_sstr = str(img_single)</span></span><br><span class="line">                <span class="comment">#img_src = re.search(r'(https[^"]+)', img_sstr).groups()[0]</span></span><br><span class="line">                img_src = img_single[<span class="string">'data-src'</span>]</span><br><span class="line">                print(type(img_src))</span><br><span class="line">                print(img_src)</span><br><span class="line">                print(<span class="string">'正在保存图片'</span>+img_src)</span><br><span class="line">                r = requests.get(img_src,stream=<span class="keyword">True</span>)</span><br><span class="line">                <span class="keyword">with</span> open(<span class="string">'d/img/'</span>+filename, <span class="string">'wb'</span>) <span class="keyword">as</span> img_f:</span><br><span class="line">                    <span class="keyword">for</span> chunk <span class="keyword">in</span> r.iter_content():</span><br><span class="line">                        img_f.write(chunk) </span><br><span class="line">                print(<span class="string">'已保存到img文件夹下,名为:'</span>+filename)</span><br><span class="line">                data[<span class="string">'content'</span>] = data[<span class="string">'content'</span>] + <span class="string">'&lt;img src="./img/'</span> + filename + <span class="string">'"&gt;'</span> + <span class="string">'&lt;br&gt;'</span></span><br><span class="line">                i = i+<span class="number">1</span></span><br><span class="line">                time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tcon = con.get_text(strip=<span class="keyword">True</span>)</span><br><span class="line">            data[<span class="string">'content'</span>] = data[<span class="string">'content'</span>] +tcon+<span class="string">'&lt;br&gt;'</span></span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line">    <span class="comment"># with open("d/ptext.html","w",encoding='utf-8') as f:#文件写入</span></span><br><span class="line">    <span class="comment">#     f.write(data['title'])</span></span><br><span class="line">    <span class="comment">#     f.write(data['content'])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_rows</span><span class="params">(path,headers,data)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(path , <span class="string">"a+"</span>, encoding=<span class="string">"gb18030"</span> , newline=<span class="string">""</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f_csv = csv.DictWriter(f,headers)</span><br><span class="line">        f_csv.writeheader()</span><br><span class="line">        f_csv.writerows(data)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">"https://mp.weixin.qq.com/s/aMxcnG7pd5C3H-6LRzgwcg"</span></span><br><span class="line">    filename = <span class="string">'qq.csv'</span></span><br><span class="line">    data = []</span><br><span class="line">    data.append(get_data(url))</span><br><span class="line">    top = [<span class="string">'title'</span>,<span class="string">'content'</span>]</span><br><span class="line">    write_rows(filename,top,data)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>[1]</p>
  
	</div>
		<footer class="article-footer clearfix">




<div class="article-share" id="share">

  <div data-url="http://yoursite.com/2018/08/06/用python爬取网页内容/" data-title="用python爬取网页内容 | L技术小筑" data-tsina="" class="share clearfix">
  </div>

</div>
</footer>   	       
	</article>
	
<nav class="article-nav clearfix">
 

<div class="next">
<a href="/2018/08/01/js的this详解/"  title="js的this详解">
 <strong>NEXT:</strong><br/> 
 <span>js的this详解
</span>
</a>
</div>

</nav>

	


</div>  
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">Contents</strong>
  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#引入各种模块"><span class="toc-number">1.</span> <span class="toc-text">引入各种模块</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#获取网页内容"><span class="toc-number">2.</span> <span class="toc-text">获取网页内容</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#对内容进行整理"><span class="toc-number">3.</span> <span class="toc-text">对内容进行整理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#处理接收到的内容"><span class="toc-number">3.1.</span> <span class="toc-text">处理接收到的内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#查找title标签的中的内容"><span class="toc-number">3.2.</span> <span class="toc-text">查找title标签的中的内容</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#查找所有P标签"><span class="toc-number">3.3.</span> <span class="toc-text">查找所有P标签</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#查看P标签中是否包含图片"><span class="toc-number">3.3.1.</span> <span class="toc-text">查看P标签中是否包含图片</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#将P标签中的内容提取出来"><span class="toc-number">3.3.2.</span> <span class="toc-text">将P标签中的内容提取出来</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#将爬去的内容存储到文件中"><span class="toc-number">3.4.</span> <span class="toc-text">将爬去的内容存储到文件中</span></a></li></ol></li></ol>
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  

  

  <div class="rsspart">
	<a href="" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<div class="social-font" class="clearfix">
		
		
		
		
	</div>
		<p class="copyright">Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/zhyu/yaht" target="_blank" title="YAHT">YAHT</a> © 2018 
		
		<a href="http://yoursite.com" target="_blank" title="John Doe">John Doe</a>
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.1.0.min.js"></script>
<script type="text/javascript">
  $(document).ready(function(){
    $('.navbar').click(function(){
      $('header nav').toggleClass('shownav');
    });
    var myWidth = 0;
    function getSize(){
      if( typeof( window.innerWidth ) == 'number' ) {
        myWidth = window.innerWidth;
      } else if( document.documentElement && document.documentElement.clientWidth) {
        myWidth = document.documentElement.clientWidth;
      };
    };
    var m = $('#main'),
    a = $('#asidepart'),
    c = $('.closeaside'),
    o = $('.openaside');
    $(window).resize(function(){
      getSize();
      if (myWidth >= 1024) {
        $('header nav').removeClass('shownav');
      }else
      {
        m.removeClass('moveMain');
        a.css('display', 'block').removeClass('fadeOut');
        o.css('display', 'none');
        
            $('#toc.toc-aside').css('display', 'none');
          
      }
    });
    c.click(function(){
      a.addClass('fadeOut').css('display', 'none');
      o.css('display', 'block').addClass('fadeIn');
      m.addClass('moveMain');
    });
    o.click(function(){
      o.css('display', 'none').removeClass('beforeFadeIn');
      a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');
      m.removeClass('moveMain');
    });
    $(window).scroll(function(){
      o.css("top",Math.max(80,260-$(this).scrollTop()));
    });
  });
</script>

  <script type="text/javascript">
    $(document).ready(function(){
      var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
      if(ai.length>0){
        ai.wrap('<div class="video-container" />');
      };
      if(ae.length>0){
        ae.wrap('<div class="video-container" />');
      };
      if(ah.length==0){
        t.css('display','none');
      }else{
        c.click(function(){
          ta.css('display', 'block').addClass('fadeIn');
        });
        o.click(function(){
          ta.css('display', 'none');
        });
        $(window).scroll(function(){
          ta.css("top",Math.max(140,320-$(this).scrollTop()));
        });
      };
    });
  </script>


  <script type="text/javascript">
    $(document).ready(function(){
      var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina');
      var html = [
        '<a href="#" class="overlay" id="qrcode"></a>',
        '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#share"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
        '<a href="#textlogo" class="article-back-to-top" title="Top"></a>',
        '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
        '<a href="#qrcode" class="article-share-qrcode" title="QRcode"></a>',
        '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
        '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="Weibo"></a>',
        '<span title="Share to"></span>'
        ].join('');
        $this.append(html);
        $('.article-share-qrcode').click(function(){
          var imgSrc = $('#qrcode-pic').attr('data-src');
          $('#qrcode-pic').attr('src', imgSrc);
          $('#qrcode-pic').load(function(){
            $('.qrcode strong').text(' ');
          });
        });
    });
  </script>


  
  






  <div id="back-to-top">
    <a title="Back to Top"><img src="/img/scrollup.png"/></a>
  </div>
  <script src="/js/back_to_top.js"></script>



  </body>
</html>
